metadata:
  name: opensearch-${THIS_NAMESPACE}
  namespace: argocd
spec:
  destination:
    namespace: ${THIS_NAMESPACE}
    server: https://kubernetes.default.svc
  project: default
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - ServerSideApply=false
  source:
    path: opensearch
    repoURL: ${THIS_REPO_URL}
    targetRevision: HEAD
    helm:
      values: |
        ---
        clusterName: "opensearch-cluster"
        nodeGroup: "master"
        
        # If discovery.type in the opensearch configuration is set to "single-node",
        # this should be set to "true"
        # If "true", replicas will be forced to 1
        singleNode: false
        
        # The service that non master groups will try to connect to when joining the cluster
        # This should be set to clusterName + "-" + nodeGroup for your master group
        masterService: "opensearch-cluster-master"
        
        # OpenSearch roles that will be applied to this nodeGroup
        # These will be set as environment variable "node.roles". E.g. node.roles=master,ingest,data,remote_cluster_client
        roles:
          - master
          - ingest
          - data
          - remote_cluster_client
        
        replicas: 3
        
        # if not set, falls back to parsing .Values.imageTag, then .Chart.appVersion.
        majorVersion: ""
        # such as opensearch.yml and log4j2.properties
        config:
          # Values must be YAML literal style scalar / YAML multiline string.
          # <filename>: |
          #   <formatted-value(s)>
          # log4j2.properties: |
          #   status = error
          #
          #   appender.console.type = Console
          #   appender.console.name = console
          #   appender.console.layout.type = PatternLayout
          #   appender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %m%n
          #
          #   rootLogger.level = info
          #   rootLogger.appenderRef.console.ref = console
          opensearch.yml: |
            cluster.name: opensearch-cluster
        
            # Bind to all interfaces because we don't know what IP address Docker will assign to us.
            network.host: 0.0.0.0
        
            # Setting network.host to a non-loopback address enables the annoying bootstrap checks. "Single-node" mode disables them again.
            # Implicitly done if ".singleNode" is set to "true".
            # discovery.type: single-node
        
            # Start OpenSearch Security Demo Configuration
            # WARNING: revise all the lines below before you go into production
            # plugins:
            #   security:
            #     ssl:
            #       transport:
            #         pemcert_filepath: esnode.pem
            #         pemkey_filepath: esnode-key.pem
            #         pemtrustedcas_filepath: root-ca.pem
            #         enforce_hostname_verification: false
            #       http:
            #         enabled: true
            #         pemcert_filepath: esnode.pem
            #         pemkey_filepath: esnode-key.pem
            #         pemtrustedcas_filepath: root-ca.pem
            #     allow_unsafe_democertificates: true
            #     allow_default_init_securityindex: true
            #     authcz:
            #       admin_dn:
            #         - CN=kirk,OU=client,O=client,L=test,C=de
            #     audit.type: internal_opensearch
            #     enable_snapshot_restore_privilege: true
            #     check_snapshot_restore_write_privileges: true
            #     restapi:
            #       roles_enabled: ["all_access", "security_rest_api_access"]
            #     system_indices:
            #       enabled: true
            #       indices:
            #         [
            #           ".opendistro-alerting-config",
            #           ".opendistro-alerting-alert*",
            #           ".opendistro-anomaly-results*",
            #           ".opendistro-anomaly-detector*",
            #           ".opendistro-anomaly-checkpoints",
            #           ".opendistro-anomaly-detection-state",
            #           ".opendistro-reports-*",
            #           ".opendistro-notifications-*",
            #           ".opendistro-notebooks",
            #           ".opendistro-asynchronous-search-response*",
            #         ]
            ######## End OpenSearch Security Demo Configuration ########
          # log4j2.properties:
        
        # Extra environment variables to append to this nodeGroup
        # This will be appended to the current 'env:' key. You can use any of the kubernetes env
        # syntax here
        extraEnvs: []
        #  - name: MY_ENVIRONMENT_VAR
        #    value: the_value_goes_here
        # Chart version 2.18.0 and App Version OpenSearch 2.12.0 onwards a custom strong password needs to be provided in order to setup demo admin user.
        # Cluster will not spin-up without this unless demo config install is disabled.
        #  - name: OPENSEARCH_INITIAL_ADMIN_PASSWORD
        #    value: <strong-password>
        
        # Allows you to load environment variables from kubernetes secret or config map
        envFrom:
          - secretRef:
              name: ${THIS_OPENSEARCH_ADMIN_CRED_SECRET}
        # - secretRef:
        #     name: env-secret
        # - configMapRef:
        #     name: config-map
        
        persistence:
          enabled: true
          # Set to false to disable the `fsgroup-volume` initContainer that will update permissions on the persistent disk.
          enableInitChown: true
          # override image, which is busybox by default
          # image: busybox
          # override image tag, which is latest by default
          # imageTag:
          labels:
            # Add default labels for the volumeClaimTemplate of the StatefulSet
            enabled: false
            # Add custom labels for the volumeClaimTemplate of the StatefulSet
            additionalLabels: {}
          # OpenSearch Persistent Volume Storage Class
          # If defined, storageClassName: <storageClass>
          # If set to "-", storageClassName: "", which disables dynamic provisioning
          # If undefined (the default) or set to null, no storageClassName spec is
          #   set, choosing the default provisioner.  (gp2 on AWS, standard on
          #   GKE, AWS & OpenStack)
          #
          storageClass: "${THIS_STORAGECLASS}"
          accessModes:
            - ReadWriteOnce
          size: ${THIS_OPENSEARCH_NODEPOOL_DISK_SIZE}
          annotations: {}
        # Enabling this will publically expose your OpenSearch instance.
        # Only enable this if you have security enabled on your cluster
        ingress:
          enabled: true
          ingressClassName: ${THIS_CLUSTER_INGRESS}
          annotations:
            nginx.ingress.kubernetes.io/rewrite-target: /
            cert-manager.io/cluster-issuer: ${THIS_CLUSTER_ISSUER}
            spec.ingressClassName: ${THIS_CLUSTER_INGRESS}
            kubernetes.io/ingress.class: ${THIS_CLUSTER_INGRESS}
            kubernetes.io/tls-acme: "true"
          path: /
          hosts:
            - ${THIS_OPENSEARCH_HOST}.${THIS_DOMAIN}
          tls:
            - secretName: opensearch-helm-${THIS_NAME}-ingress-tls
              hosts:
                - ${THIS_OPENSEARCH_HOST}.${THIS_DOMAIN}
